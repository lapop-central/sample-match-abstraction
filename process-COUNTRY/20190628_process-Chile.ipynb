{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz, process\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "country = \"CL\"\n",
    "geo2_nq = \"CL_comuna\"\n",
    "geo1_nq = \"CL_provincia\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "census = pd.read_csv(\"../Data/\"+country+\"/sample/\"+\"ipumsi_00020.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "netquest = pd.read_csv(\"../Data/\"+country+\"/panel/\"+country+\"_netquest-panel.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipums_geo2 = pd.read_csv('../Data/CL/sample/ipums_codebook_GEO2_CL2002.csv',encoding='Latin1', names=['code','name'], skiprows=1)\n",
    "ipums_geo1 = pd.read_csv('../Data/'+country+'/sample/ipums_codebook_GEO1_CL2002.csv',encoding='Latin1', names=['code','name'], skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\schadem\\AppData\\Local\\Continuum\\anaconda3\\envs\\idb\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\schadem\\AppData\\Local\\Continuum\\anaconda3\\envs\\idb\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\schadem\\AppData\\Local\\Continuum\\anaconda3\\envs\\idb\\lib\\site-packages\\ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "ipums_geodf = census[['GEO1_CL2002','GEO2_CL2002']]\n",
    "ipums_geodf.columns = ['geo1_code','geo2_code']\n",
    "ipums_geodf.drop_duplicates(inplace=True)\n",
    "\n",
    "ipums_geodf['geo1_name'] = ipums_geodf.merge(ipums_geo1, \n",
    "                                             how='left', \n",
    "                                             left_on = \"geo1_code\", \n",
    "                                             right_on = 'code', \n",
    "                                             copy=False)['name'].values\n",
    "\n",
    "ipums_geodf['geo2_name'] = ipums_geodf.merge(ipums_geo2, \n",
    "                                             how='left', \n",
    "                                             left_on = \"geo2_code\", \n",
    "                                             right_on = 'code', \n",
    "                                             copy=False)['name'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to get the melting action going here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipums_geodf = ipums_geodf.geo2_name.str.split(',').apply(pd.Series) \\\n",
    "    .merge(ipums_geodf, right_index = True, left_index = True) \\\n",
    "    .drop([\"geo2_name\"], axis = 1) \\\n",
    "    .melt(id_vars = [k for k in ipums_geodf.columns if not (type(k)==int)|(k=='geo2_name')], value_name = \"geo2_name\") \\\n",
    "    .drop(\"variable\", axis = 1) \\\n",
    "    .dropna(subset=['geo2_name'])\n",
    "ipums_geodf.geo2_name = ipums_geodf.geo2_name.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipums_geodf = ipums_geodf.geo1_name.str.split(',').apply(pd.Series) \\\n",
    "    .merge(ipums_geodf, right_index = True, left_index = True) \\\n",
    "    .drop([\"geo1_name\"], axis = 1) \\\n",
    "    .melt(id_vars = [k for k in ipums_geodf.columns if not (type(k)==int)|(k=='geo1_name')], value_name = \"geo1_name\") \\\n",
    "    .drop(\"variable\", axis = 1) \\\n",
    "    .dropna(subset=['geo1_name'])\n",
    "ipums_geodf.geo1_name = ipums_geodf.geo1_name.str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to Netquest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\schadem\\AppData\\Local\\Continuum\\anaconda3\\envs\\idb\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\schadem\\AppData\\Local\\Continuum\\anaconda3\\envs\\idb\\lib\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "province_labels = pd.read_excel(\"../Data/CL/panel/provincia_dict.xlsx\", \n",
    "                                encoding='Latin1', header=None)\n",
    "nq_geodf = netquest[[geo1_nq,geo2_nq,geo2_nq+'_name']]\n",
    "nq_geodf.columns = ['geo1_code','geo2_code','geo2_name']\n",
    "\n",
    "#the following is Chile-specific\n",
    "nq_geodf['geo1_name'] = netquest.CL_provincia.fillna(-99\n",
    "                                                 ).astype(int\n",
    "                                                ).replace(province_labels[1].values,\n",
    "                                                   province_labels[0].values\n",
    "                                                  )\n",
    "nq_geodf.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the duplicates in nq_geodf.geo2_code, and keeping the combinations that occur most often (which are quite clearly the good ones)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\schadem\\AppData\\Local\\Continuum\\anaconda3\\envs\\idb\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "nq_geodf['count'] = nq_geodf.apply(lambda r: sum((netquest[geo1_nq]==r['geo1_code'])&(netquest[geo2_nq]==r['geo2_code'])),\n",
    "                                   axis=1)\n",
    "nq_geodf = nq_geodf.sort_values(['geo2_code','count']) \\\n",
    "    [~(nq_geodf.sort_values(['geo2_code','count']).duplicated('geo2_code',keep='last'))]\n",
    "# tmp = nq_geodf[~(nq_geodf.sort_values(['geo2_code','count']).duplicated('geo2_code',keep='last'))]\n",
    "#nq_geodf = nq_geodf[~((nq_geodf.geo2_code.duplicated(keep=False))&(nq_geodf['count']<2))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manual fixes, as found necessary in the next step..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "nq_geodf.loc[nq_geodf.geo1_name==\"Marga Marga\",'geo1_name'] = 'Valparaíso'\n",
    "nq_geodf.loc[nq_geodf.geo1_name==\"Aysen\",'geo1_name'] = 'Aisén'\n",
    "\n",
    "nq_geodf.loc[nq_geodf.geo1_name==\"Diguillin\",'geo1_name'] = 'Ñuble'\n",
    "nq_geodf.loc[nq_geodf.geo1_name==\"Itata\",'geo1_name'] = 'Ñuble'\n",
    "nq_geodf.loc[nq_geodf.geo1_name==\"Punilla\",'geo1_name'] = 'Ñuble'\n",
    "\n",
    "ipums_geodf.loc[ipums_geodf.geo2_name.str.contains(\"San Fernando\"),\n",
    "                'geo1_name'] = \"Colchagua\"\n",
    "ipums_geodf.loc[ipums_geodf.geo2_name.str.contains(\"Chimbarongo\"),\n",
    "                'geo1_name'] = \"Colchagua\"\n",
    "ipums_geodf.loc[ipums_geodf.geo2_name.str.contains(\"Palmilla\"),\n",
    "                'geo1_name'] = \"Colchagua\"\n",
    "ipums_geodf.loc[ipums_geodf.geo2_name.str.contains(\"Nancagua\"),\n",
    "                'geo1_name'] = \"Colchagua\"\n",
    "ipums_geodf.loc[ipums_geodf.geo2_name.str.contains(\"Chépica\"),\n",
    "                'geo1_name'] = \"Colchagua\"\n",
    "ipums_geodf.loc[ipums_geodf.geo2_name.str.contains(\"Pumanque\"),\n",
    "                'geo1_name'] = \"Colchagua\"\n",
    "ipums_geodf.loc[ipums_geodf.geo2_name.str.contains(\"Placilla\"),\n",
    "                'geo1_name'] = \"Colchagua\"\n",
    "ipums_geodf.loc[ipums_geodf.geo2_name.str.contains(\"Lolol\"),\n",
    "                'geo1_name'] = \"Colchagua\"\n",
    "ipums_geodf.loc[ipums_geodf.geo2_name.str.contains(\"Peralillo\"),\n",
    "                'geo1_name'] = \"Colchagua\"\n",
    "ipums_geodf.loc[ipums_geodf.geo2_name.str.contains(\"Santa Cruz\"),\n",
    "                'geo1_name'] = \"Colchagua\"\n",
    "\n",
    "ipums_geodf.loc[ipums_geodf.geo2_name==\"Pozo Almonte\",'geo1_name'] = 'Tamarugal'\n",
    "ipums_geodf.loc[ipums_geodf.geo2_name.str.contains(\"Lago Ranco\"),'geo1_name'] = 'Ranco'\n",
    "ipums_geodf.loc[ipums_geodf.geo2_name.str.contains(\"Futrono\"),\n",
    "                'geo1_name'] = \"Ranco\"\n",
    "ipums_geodf.loc[ipums_geodf.geo2_name.str.contains(\"Río Bueno\"),\n",
    "                'geo1_name'] = \"Ranco\"\n",
    "ipums_geodf.loc[ipums_geodf.geo2_name.str.contains(\"La Unión\"),\n",
    "                'geo1_name'] = \"Ranco\"\n",
    "\n",
    "ipums_geodf.loc[ipums_geodf.geo2_name.str.contains(\"Olmué\"),'geo1_name'] = 'Valparaíso'\n",
    "ipums_geodf.loc[ipums_geodf.geo2_name==\"Limache\",'geo1_name'] = 'Valparaíso'\n",
    "nq_geodf.loc[nq_geodf.geo2_name==\"Limache\",'geo1_name'] = 'Valparaíso'\n",
    "nq_geodf.loc[nq_geodf.geo2_name==\"San Antonio\",'geo1_name'] = 'San Antonio'\n",
    "\n",
    "nq_geodf.loc[nq_geodf.geo2_name==\"Alto Hospicio\",'geo2_name'] = 'Iquique'\n",
    "nq_geodf.loc[nq_geodf.geo2_name==\"Hualpén\",'geo2_name'] = 'Talcahuano'\n",
    "nq_geodf.loc[nq_geodf.geo2_name==\"Cholchol\",'geo2_name'] = 'Nueva Imperial'\n",
    "nq_geodf.loc[nq_geodf.geo2_name==\"Alto Bío-Bí\",'geo2_name'] = 'Santa Bárbara'\n",
    "nq_geodf.loc[nq_geodf.geo2_name==\"Antofagasta\",'geo1_name'] = 'Antofagasta'\n",
    "nq_geodf.loc[nq_geodf.geo2_name==\"Chillán\",'geo1_name'] = 'Ñuble'\n",
    "nq_geodf.loc[nq_geodf.geo2_name==\"Colbún\",'geo1_name'] = 'Linares'\n",
    "nq_geodf.loc[nq_geodf.geo2_name==\"Coquimbo\",'geo1_name'] = 'Elqui'\n",
    "nq_geodf.loc[nq_geodf.geo2_name==\"Maipú\",'geo1_name'] = 'Santiago'\n",
    "nq_geodf.loc[nq_geodf.geo2_name==\"Quilicura\",'geo1_name'] = 'Santiago'\n",
    "nq_geodf.loc[nq_geodf.geo2_name==\"Maipú\",'geo1_name'] = 'Santiago'\n",
    "nq_geodf.loc[nq_geodf.geo2_name==\"Puente Alto\",'geo1_name'] = 'Cordillera'\n",
    "nq_geodf.loc[nq_geodf.geo2_name==\"Pirque\",'geo1_name'] = 'Cordillera'\n",
    "nq_geodf.loc[nq_geodf.geo2_name==\"Peñaflor\",'geo1_name'] = 'Talagante'\n",
    "nq_geodf.loc[nq_geodf.geo2_name==\"Buin\",'geo1_name'] = 'Maipo'\n",
    "nq_geodf.loc[nq_geodf.geo2_name==\"San Bernardo\",'geo1_name'] = 'Maipo'\n",
    "\n",
    "ipums_geodf.loc[ipums_geodf.geo2_name.isin([\"Talcahuano\",\n",
    "                                            \"Concepción\",\n",
    "                                            \"Coronel\",\n",
    "                                            \"Lota\"\n",
    "                                           ]),\n",
    "                'geo1_name'] = \"Concepción\"\n",
    "\n",
    "nq_geodf.loc[nq_geodf.geo2_name.isin([\"Talcahuano\",\n",
    "                                            \"Concepción\",\n",
    "                                            \"Coronel\",\n",
    "                                            \"Lota\"\n",
    "                                           ]),\n",
    "                'geo1_name'] = \"Concepción\"\n",
    "\n",
    "nq_geodf.loc[nq_geodf.geo2_name.isin([\"Colchane\",'Pica','Huara',\"Camiña\",\n",
    "                                           ]),\n",
    "                'geo1_name'] = \"Iquique\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll have to merge together the two names for matching. ACtually, I don't think that will work given the obnoxious abbreviations... I'll have to see about this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuzzy_join(df1, df2, varname, subset=False, cutoff=90):\n",
    "    '''Returns a dataframe the length of df1, with the matches on the given variable\n",
    "    \n",
    "        Assumes the var is named the same in both dataframes.\n",
    "        \n",
    "        subset is a tuple or list of length 2 whose first element is a string indicating which\n",
    "        variable in df1 has to be equal to which variable in df2 (specified by 2nd element)\n",
    "        '''\n",
    "    #figure out if there is a constraint\n",
    "    if not subset:\n",
    "        #match #1\n",
    "        ratio_matches = df1.astype(str).apply(\n",
    "                lambda d: process.extract(d[varname], \n",
    "                                             df2[varname].astype(str).drop_duplicates(),\n",
    "                                             scorer=fuzz.ratio, limit=2\n",
    "                                            ), axis=1)\n",
    "        #match #2\n",
    "        parti_matches = df1.astype(str).apply(\n",
    "                lambda d: process.extract(d[varname], \n",
    "                                             df2[varname].astype(str).drop_duplicates(),\n",
    "                                             scorer=fuzz.partial_ratio, limit=2\n",
    "                                            ), axis=1)\n",
    "        \n",
    "    else:\n",
    "        #match #1\n",
    "        ratio_matches = df1.astype(str).apply(\n",
    "                lambda d: process.extract(d[varname], \n",
    "                                             df2[varname][df2[subset[1]]==d[subset[0]]].astype(str).drop_duplicates(),\n",
    "                                             scorer=fuzz.ratio, limit=2\n",
    "                                            ), axis=1)\n",
    "        #match #2\n",
    "        parti_matches = df1.astype(str).apply(\n",
    "                lambda d: process.extract(d[varname], \n",
    "                                             df2[varname][df2[subset[1]]==d[subset[0]]].astype(str).drop_duplicates(),\n",
    "                                             scorer=fuzz.partial_ratio, limit=2\n",
    "                                            ), axis=1)    \n",
    "\n",
    "    \n",
    "    # different match cases\n",
    "    #morRatioMatch = ratio_matches.apply(lambda l: (l[0][1]==100)&(l[1][1]==100))\n",
    "    oneRatioMatch = ratio_matches.apply(lambda l: (l[0][1]>=cutoff))#&(l[1][1]<100))\n",
    "    noRatioMatch = ratio_matches.apply(lambda l: (l[0][1]<cutoff))\n",
    "\n",
    "    #morPartiMatch = parti_matches.apply(lambda l: (l[0][1]==100)&(l[1][1]==100))\n",
    "    onePartiMatch = parti_matches.apply(lambda l: (l[0][1]>=cutoff))#&(l[1][1]<100))\n",
    "    noPartiMatch = parti_matches.apply(lambda l: (l[0][1]<cutoff))\n",
    "    \n",
    "    # pick out what's better\n",
    "    matches = pd.Series([(np.nan,np.nan,np.nan)]*len(df1),index=df1.index)\n",
    "    matches.loc[oneRatioMatch] = ratio_matches.loc[oneRatioMatch].apply(lambda l: l[0])\n",
    "    matches.loc[(noRatioMatch&onePartiMatch)] = parti_matches.loc[(noRatioMatch&onePartiMatch)]\\\n",
    "        .apply(lambda l: l[0])\n",
    "    matches.loc[(noRatioMatch&noPartiMatch)] = parti_matches.loc[(noRatioMatch&noPartiMatch)]\\\n",
    "        .apply(lambda l: l[0])\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    df['name'] = matches.apply(lambda l: l[0])\n",
    "    df['score'] = matches.apply(lambda l: l[1])\n",
    "    df['index'] = matches.apply(lambda l: l[2])\n",
    "    df['parti_matches'] = parti_matches\n",
    "    df['ratio_matches'] = ratio_matches\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the new tool!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nq_geodf[['geo1_match_name','geo1_match_score','geo1_match_index']] \\\n",
    "= fuzzy_join(nq_geodf, ipums_geodf, 'geo1_name')[['name','score','index']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "nq_geodf[['geo2_match_name','geo2_match_score','geo2_match_index']] \\\n",
    "= fuzzy_join(nq_geodf, ipums_geodf, 'geo2_name', \n",
    "             subset=['geo1_match_name','geo1_name']\n",
    "            )[['name','score','index']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## De-duping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What can we eliminate? Where geo_2code is duplicated and...\n",
    "* where geo2_code and geo2_match_code are duplicated across dupes, just de-dupe--doesn't matter which we use\n",
    "* drop any that have NaN in their geo-s\n",
    "* one of the geo2_match_names is an exact match, throw out any others\n",
    "* if there are two contenders, check which code+geo1_name+geo2_name combo has the majority--thankfully doesn't seem to be necessary here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = nq_geodf.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # if we have the same mapping between netquest geo2 and ipums geo2, doesn't matter which we pick\n",
    "# tmp = tmp.drop_duplicates(subset=['geo2_code','geo2_match_index'])\n",
    "# # ones that have NA geographies are useless in this context, so drop them first\n",
    "# tmp = tmp[(~tmp.geo1_code.isna())& (~tmp.geo2_code.isna())]\n",
    "\n",
    "# dupes = tmp[tmp.duplicated('geo2_code')].geo2_code\n",
    "# for code in dupes: \n",
    "#     # if one of the geo2_match_names is an exact match, throw out any others\n",
    "#     if sum(tmp.loc[tmp.geo2_code==code,\"geo2_name\"]==tmp.loc[tmp.geo2_code==code,\"geo2_match_name\"])>0:\n",
    "#         tmp = tmp[~((tmp.geo2_code==code) & (tmp.geo2_name!=tmp.geo2_match_name))]\n",
    "#     # if there are still duplicates, use the one that has the most prevalent pairing of geo1 & geo2\n",
    "# #     id_of_most_common = tmp.loc[tmp.geo2_code==code,\"geo1_code\"].apply(\n",
    "# #         lambda c: sum((netquest[geo1_nq]==c) & (netquest[geo2_nq]==code))\n",
    "# #     ).idxmax()\n",
    "# #     correct_geo1 = tmp.loc[id_of_most_common,\"geo1_code\"]\n",
    "# #     tmp = tmp[~((tmp.geo2_code==code) & ~(tmp.geo1_code==correct_geo1))]\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is still an issue??**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geo2_code</th>\n",
       "      <th>geo1_name</th>\n",
       "      <th>geo1_match_name</th>\n",
       "      <th>geo2_name</th>\n",
       "      <th>geo2_match_name</th>\n",
       "      <th>geo2_match_score</th>\n",
       "      <th>geo2_match_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [geo2_code, geo1_name, geo1_match_name, geo2_name, geo2_match_name, geo2_match_score, geo2_match_index]\n",
       "Index: []"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp[tmp.duplicated('geo2_code', keep=False)].sort_values('geo2_code')\\\n",
    "[[\"geo2_code\",\"geo1_name\",\"geo1_match_name\",\"geo2_name\",\"geo2_match_name\",\"geo2_match_score\",\"geo2_match_index\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some testing..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geo1_name</th>\n",
       "      <th>geo1_match_name</th>\n",
       "      <th>geo2_name</th>\n",
       "      <th>geo2_match_name</th>\n",
       "      <th>geo2_match_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3189</th>\n",
       "      <td>Aisén</td>\n",
       "      <td>Aisén</td>\n",
       "      <td>Aysen</td>\n",
       "      <td>Aisén</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1141</th>\n",
       "      <td>Cachapoal</td>\n",
       "      <td>Cachapoal</td>\n",
       "      <td>Doñihue</td>\n",
       "      <td>Doñigue</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>Cachapoal</td>\n",
       "      <td>Cachapoal</td>\n",
       "      <td>Machalí</td>\n",
       "      <td>Machali</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1385</th>\n",
       "      <td>Cachapoal</td>\n",
       "      <td>Cachapoal</td>\n",
       "      <td>Requínoa</td>\n",
       "      <td>Requinoa</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7370</th>\n",
       "      <td>Curicó</td>\n",
       "      <td>Curicó</td>\n",
       "      <td>Hualañé</td>\n",
       "      <td>Hualañe</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47785</th>\n",
       "      <td>El Loa</td>\n",
       "      <td>El Loa</td>\n",
       "      <td>Ollagüe</td>\n",
       "      <td>Ollague</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1697</th>\n",
       "      <td>Linares</td>\n",
       "      <td>Linares</td>\n",
       "      <td>Longaví</td>\n",
       "      <td>Longavi</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2855</th>\n",
       "      <td>Llanquihue</td>\n",
       "      <td>Llanquihue</td>\n",
       "      <td>Maullín</td>\n",
       "      <td>Maullin</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>Malleco</td>\n",
       "      <td>Malleco</td>\n",
       "      <td>Traiguén</td>\n",
       "      <td>Traiguen</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>Melipilla</td>\n",
       "      <td>Melipilla</td>\n",
       "      <td>Curacaví</td>\n",
       "      <td>Curacavi</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2104</th>\n",
       "      <td>Osorno</td>\n",
       "      <td>Osorno</td>\n",
       "      <td>Río Negro</td>\n",
       "      <td>Rio Negro</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374690</th>\n",
       "      <td>Osorno</td>\n",
       "      <td>Osorno</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Purranque</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3984</th>\n",
       "      <td>Talca</td>\n",
       "      <td>Talca</td>\n",
       "      <td>Río Claro</td>\n",
       "      <td>Rio Claro</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         geo1_name geo1_match_name  geo2_name geo2_match_name  \\\n",
       "3189         Aisén           Aisén      Aysen           Aisén   \n",
       "1141     Cachapoal       Cachapoal    Doñihue         Doñigue   \n",
       "159      Cachapoal       Cachapoal    Machalí         Machali   \n",
       "1385     Cachapoal       Cachapoal   Requínoa        Requinoa   \n",
       "7370        Curicó          Curicó    Hualañé         Hualañe   \n",
       "47785       El Loa          El Loa    Ollagüe         Ollague   \n",
       "1697       Linares         Linares    Longaví         Longavi   \n",
       "2855    Llanquihue      Llanquihue    Maullín         Maullin   \n",
       "350        Malleco         Malleco   Traiguén        Traiguen   \n",
       "207      Melipilla       Melipilla   Curacaví        Curacavi   \n",
       "2104        Osorno          Osorno  Río Negro       Rio Negro   \n",
       "374690      Osorno          Osorno        NaN       Purranque   \n",
       "3984         Talca           Talca  Río Claro       Rio Claro   \n",
       "\n",
       "        geo2_match_score  \n",
       "3189                  60  \n",
       "1141                  86  \n",
       "159                   86  \n",
       "1385                  88  \n",
       "7370                  86  \n",
       "47785                 86  \n",
       "1697                  86  \n",
       "2855                  86  \n",
       "350                   88  \n",
       "207                   88  \n",
       "2104                  89  \n",
       "374690                67  \n",
       "3984                  89  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp[tmp.geo2_match_score<90][['geo1_name',\n",
    "                                        'geo1_match_name',\n",
    "                                        'geo2_name',\n",
    "                                        'geo2_match_name',\n",
    "                                        'geo2_match_score']\n",
    "                                      ].sort_values('geo1_match_name'\n",
    "                                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Success! This can be the geo-df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "nq_geodf = tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a crosswalk for these!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "has_ipums_geo = nq_geodf.geo2_match_index.notna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nq_geodf['IPUMS_geo2_code'] = np.nan\n",
    "\n",
    "nq_geodf.loc[has_ipums_geo,'IPUMS_geo2_code'] = nq_geodf[has_ipums_geo]\\\n",
    "                            .geo2_match_index\\\n",
    "                            .astype(int)\\\n",
    "                            .apply(\n",
    "                                lambda i: ipums_geodf.loc[i,'geo2_code']\n",
    "                            .astype(int)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to replace each nq_geo2 with the _code_ for the corresponding census geography.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the municipio-centroids, and hopefully attach them here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo2_centroids = pd.read_csv('../Data/'+country+'/geography/'+country+'_geo_centroids.csv', encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "nq_geodf = nq_geodf.merge(geo2_centroids[['ADMIN_NAME','Y','X','IPUM2002']], \n",
    "               left_on='IPUMS_geo2_code',\n",
    "               right_on=\"IPUM2002\",\n",
    "               how='left'\n",
    "              ).drop('IPUM2002', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "panel_geo = netquest.merge(nq_geodf[['X','Y','geo2_code']],\n",
    "               left_on=geo2_nq,\n",
    "               right_on='geo2_code',\n",
    "               how='left'\n",
    "              ).drop('geo2_code',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "panel_geo.shape[0]==netquest.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "panel_geo.to_csv('../Data/'+country+'/panel/'+country+'_netquest-panel_geo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_geo = census.merge(geo2_centroids[['ADMIN_NAME','X',\"Y\",'IPUM2002']],\n",
    "                          left_on = 'GEO2_CL2002',\n",
    "                          right_on='IPUM2002',\n",
    "                          how='left'\n",
    "                         ).drop('IPUM2002',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census_geo.shape[0]==census.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_geo.to_csv('../Data/'+country+'/sample/'+country+'_ipums-census_geo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
