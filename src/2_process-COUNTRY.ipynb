{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz, process\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting names, files, and parameters\n",
    "These can go into a dictionary _I believe_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "country = \"AR\"\n",
    "nq_date = \"191018\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "census = pd.read_csv(\"../../raw/ipums/\"+country+\"/ipumsi_00015.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\schadem\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3020: DtypeWarning: Columns (23,549) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "netquest = pd.read_csv(\"../../../Data/\"+country+\"/panel/\"+country+\"_netquest-panel.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nq_dict = pd.read_excel(\"../../../Data/AR/panel/AR_levels.xlsx\",\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo1_nq = \"AR_provincia\"\n",
    "geo2_nq = \"AR_departamento\"\n",
    "geo1_ipums = 'GEO1_AR2010'\n",
    "geo2_ipums = 'GEO2_AR2010'\n",
    "year = '2010'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipums_geo2 = pd.read_csv('../../../Data/'+country+'/sample/ipums_codebook_'+geo2_ipums+'.csv',encoding='Latin1', names=['code','name'], skiprows=1)\n",
    "ipums_geo1 = pd.read_csv('../../../Data/'+country+'/sample/ipums_codebook_'+geo1_ipums+'.csv',encoding='Latin1', names=['code','name'], skiprows=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure Marcos Paz is here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>6050</td>\n",
       "      <td>Marcos Paz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>14010</td>\n",
       "      <td>Marcos Juárez</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      code           name\n",
       "64    6050     Marcos Paz\n",
       "132  14010  Marcos Juárez"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipums_geo2[ipums_geo2.name.str.contains('Marcos')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up helper structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nq_geo1 = nq_dict[nq_dict.Variable==geo1_nq]\n",
    "nq_geo1.columns = [\"Variable\",geo1_nq,geo1_nq+\"_name\"]\n",
    "nq_geo1 = nq_geo1[[geo1_nq,geo1_nq+\"_name\"]]\n",
    "\n",
    "nq_geo2 = nq_dict[nq_dict.Variable==geo2_nq]\n",
    "nq_geo2.columns = [\"Variable\",geo2_nq,geo2_nq+\"_name\"]\n",
    "nq_geo2 = nq_geo2[[geo2_nq,geo2_nq+\"_name\"]]\n",
    "# nq_geo1 = pd.read_excel(\"../Data/AR/panel/netquest_codebook_AR_provincia.xlsx\")\n",
    "\n",
    "# nq_geo2 = pd.read_excel(\"../Data/AR/panel/netquest_codebook_AR_departamento.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up the unique DF for geographies for IPUMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\schadem\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\schadem\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\schadem\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "ipums_geodf = census[[geo1_ipums,geo2_ipums]]\n",
    "ipums_geodf.columns = ['geo1_code','geo2_code']\n",
    "ipums_geodf.drop_duplicates(subset=['geo1_code','geo2_code'],inplace=True)\n",
    "\n",
    "ipums_geodf['geo1_name'] = ipums_geodf.merge(ipums_geo1, \n",
    "                                             how='left', \n",
    "                                             left_on = \"geo1_code\", \n",
    "                                             right_on = 'code', \n",
    "                                             copy=False)['name'].values\n",
    "\n",
    "ipums_geodf['geo2_name'] = ipums_geodf.merge(ipums_geo2, \n",
    "                                             how='left', \n",
    "                                             left_on = \"geo2_code\", \n",
    "                                             right_on = 'code', \n",
    "                                             copy=False)['name'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to get the melting action going here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipums_geodf = ipums_geodf.geo2_name.str.split(',').apply(pd.Series) \\\n",
    "    .merge(ipums_geodf, right_index = True, left_index = True) \\\n",
    "    .drop([\"geo2_name\"], axis = 1) \\\n",
    "    .melt(id_vars = [k for k in ipums_geodf.columns if not (type(k)==int)|(k=='geo2_name')], value_name = \"geo2_name\") \\\n",
    "    .drop(\"variable\", axis = 1) \\\n",
    "    .dropna(subset=['geo2_name'])\n",
    "ipums_geodf.geo2_name = ipums_geodf.geo2_name.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipums_geodf = ipums_geodf.geo1_name.str.split(',').apply(pd.Series) \\\n",
    "    .merge(ipums_geodf, right_index = True, left_index = True) \\\n",
    "    .drop([\"geo1_name\"], axis = 1) \\\n",
    "    .melt(id_vars = [k for k in ipums_geodf.columns if not (type(k)==int)|(k=='geo1_name')], value_name = \"geo1_name\") \\\n",
    "    .drop(\"variable\", axis = 1) \\\n",
    "    .dropna(subset=['geo1_name'])\n",
    "ipums_geodf.geo1_name = ipums_geodf.geo1_name.str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recoding certain things\n",
    "This could go to external functions to load in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accounting for the CABA mess. Reducing to just one centroid for all of CABA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipums_geodf.loc[ipums_geodf.geo1_name==\"City of Buenos Aires\",\n",
    "             'geo1_name'] = 'CABA'\n",
    "ipums_geodf.loc[(ipums_geodf.geo1_name==\"CABA\"),'geo2_name'] = 'CABA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "caba_codes = ipums_geodf[ipums_geodf.geo1_name==\"CABA\"].geo2_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping CABA-related duplicates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipums_geodf.drop_duplicates(subset=[\"geo1_name\",\"geo2_name\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(511, 4)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipums_geodf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geo1_code</th>\n",
       "      <th>geo2_code</th>\n",
       "      <th>geo2_name</th>\n",
       "      <th>geo1_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>CABA</td>\n",
       "      <td>CABA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   geo1_code  geo2_code geo2_name geo1_name\n",
       "0          2       2006      CABA      CABA"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipums_geodf[ipums_geodf.geo1_name==\"CABA\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure all CABAs in the census table have that same leftover geo2_code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2006"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipums_geodf[ipums_geodf.geo1_name==\"CABA\"].geo2_code.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "census.loc[census[geo2_ipums].isin(caba_codes),geo2_ipums] = \\\n",
    "len(census.loc[census[geo2_ipums].isin(caba_codes),geo2_ipums])*[ipums_geodf[ipums_geodf.geo1_name==\"CABA\"].geo2_code[0]]\n",
    "\n",
    "#= ipums_geodf[ipums_geodf.geo1_name==\"CABA\"].geo2_code.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to Netquest--first, get the geo1- and geo2_name in there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import barrio as departamento in CABA--actually, that turns out not to be a great idea, since it seems that these are actually partidos of the province.\n",
    "\n",
    "Instead, give these a unique code, that will be used to identify them later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# netquest.loc[netquest[geo2_nq].isna()&netquest.AR_barrio.notna(),geo2_nq\n",
    "#             ] = netquest.AR_barrio[netquest[geo2_nq].isna()&netquest.AR_barrio.notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "netquest.loc[netquest[geo2_nq].isna()&(netquest[geo1_nq]==1),geo2_nq] = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# province_labels = pd.read_excel(\"../Data/CL/provincia_dict.xlsx\", encoding='Latin1', header=None)\n",
    "nq_geodf = netquest.merge(nq_geo2, on=geo2_nq, how='left')\\\n",
    "                   .merge(nq_geo1, on=geo1_nq, how='left')[[geo1_nq,geo1_nq+'_name',geo2_nq,geo2_nq+'_name']]\n",
    "nq_geodf.columns = ['geo1_code','geo1_name','geo2_code','geo2_name']\n",
    "nq_geodf.drop_duplicates(inplace=True)\n",
    "\n",
    "# Fixing CABA not having Dept.\n",
    "nq_geodf.loc[nq_geodf.geo1_name==\"Ciudad Autónoma de Buenos Aires\",\n",
    "             'geo1_name'] = 'CABA'\n",
    "# Where province is CABA and no departamento exists, call these \"CABA\"\n",
    "# nq_geodf.loc[(nq_geodf.geo1_name==\"CABA\")&(nq_geodf.geo2_name.isna()),'geo2_name'] = 'CABA'\n",
    "\n",
    "nq_geodf = nq_geodf[(nq_geodf['geo1_code'].notna()) & (nq_geodf['geo2_code'].notna())] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geo1_code</th>\n",
       "      <th>geo1_name</th>\n",
       "      <th>geo2_code</th>\n",
       "      <th>geo2_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>CABA</td>\n",
       "      <td>999.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32832</th>\n",
       "      <td>1.0</td>\n",
       "      <td>CABA</td>\n",
       "      <td>133.0</td>\n",
       "      <td>Villarino</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104299</th>\n",
       "      <td>1.0</td>\n",
       "      <td>CABA</td>\n",
       "      <td>156.0</td>\n",
       "      <td>Sobremonte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118839</th>\n",
       "      <td>1.0</td>\n",
       "      <td>CABA</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Cañuelas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155728</th>\n",
       "      <td>1.0</td>\n",
       "      <td>CABA</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9 de Julio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168624</th>\n",
       "      <td>1.0</td>\n",
       "      <td>CABA</td>\n",
       "      <td>67.0</td>\n",
       "      <td>La Matanza</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188767</th>\n",
       "      <td>1.0</td>\n",
       "      <td>CABA</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Avellaneda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236989</th>\n",
       "      <td>1.0</td>\n",
       "      <td>CABA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25 de Mayo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        geo1_code geo1_name  geo2_code   geo2_name\n",
       "11            1.0      CABA      999.0         NaN\n",
       "32832         1.0      CABA      133.0   Villarino\n",
       "104299        1.0      CABA      156.0  Sobremonte\n",
       "118839        1.0      CABA       21.0    Cañuelas\n",
       "155728        1.0      CABA        2.0  9 de Julio\n",
       "168624        1.0      CABA       67.0  La Matanza\n",
       "188767        1.0      CABA        8.0  Avellaneda\n",
       "236989        1.0      CABA        1.0  25 de Mayo"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nq_geodf[nq_geodf.geo1_name==\"CABA\"]\n",
    "nq_geodf[nq_geodf.geo1_code==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geo1_code</th>\n",
       "      <th>geo1_name</th>\n",
       "      <th>geo2_code</th>\n",
       "      <th>geo2_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Buenos Aires</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25 de Mayo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236989</th>\n",
       "      <td>1.0</td>\n",
       "      <td>CABA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25 de Mayo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Buenos Aires</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9 de Julio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155728</th>\n",
       "      <td>1.0</td>\n",
       "      <td>CABA</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9 de Julio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Buenos Aires</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Avellaneda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188767</th>\n",
       "      <td>1.0</td>\n",
       "      <td>CABA</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Avellaneda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Buenos Aires</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Cañuelas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118839</th>\n",
       "      <td>1.0</td>\n",
       "      <td>CABA</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Cañuelas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Buenos Aires</td>\n",
       "      <td>67.0</td>\n",
       "      <td>La Matanza</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168624</th>\n",
       "      <td>1.0</td>\n",
       "      <td>CABA</td>\n",
       "      <td>67.0</td>\n",
       "      <td>La Matanza</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Buenos Aires</td>\n",
       "      <td>133.0</td>\n",
       "      <td>Villarino</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32832</th>\n",
       "      <td>1.0</td>\n",
       "      <td>CABA</td>\n",
       "      <td>133.0</td>\n",
       "      <td>Villarino</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2103</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Buenos Aires</td>\n",
       "      <td>156.0</td>\n",
       "      <td>Sobremonte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54861</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Córdoba</td>\n",
       "      <td>156.0</td>\n",
       "      <td>Sobremonte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104299</th>\n",
       "      <td>1.0</td>\n",
       "      <td>CABA</td>\n",
       "      <td>156.0</td>\n",
       "      <td>Sobremonte</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        geo1_code     geo1_name  geo2_code   geo2_name\n",
       "204           2.0  Buenos Aires        1.0  25 de Mayo\n",
       "236989        1.0          CABA        1.0  25 de Mayo\n",
       "531           2.0  Buenos Aires        2.0  9 de Julio\n",
       "155728        1.0          CABA        2.0  9 de Julio\n",
       "36            2.0  Buenos Aires        8.0  Avellaneda\n",
       "188767        1.0          CABA        8.0  Avellaneda\n",
       "83            2.0  Buenos Aires       21.0    Cañuelas\n",
       "118839        1.0          CABA       21.0    Cañuelas\n",
       "15            2.0  Buenos Aires       67.0  La Matanza\n",
       "168624        1.0          CABA       67.0  La Matanza\n",
       "516           2.0  Buenos Aires      133.0   Villarino\n",
       "32832         1.0          CABA      133.0   Villarino\n",
       "2103          2.0  Buenos Aires      156.0  Sobremonte\n",
       "54861         3.0       Córdoba      156.0  Sobremonte\n",
       "104299        1.0          CABA      156.0  Sobremonte"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nq_geodf[nq_geodf.duplicated('geo2_code', keep=False)].sort_values('geo2_code')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## removing duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the duplicates in nq_geodf.geo2_code, and keeping the combinations that occur most often (which are quite clearly the good ones)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "nq_geodf['count'] = nq_geodf.apply(\n",
    "    lambda r: sum((netquest[geo1_nq]==r['geo1_code'])&\n",
    "                  (netquest[geo2_nq]==r['geo2_code'])),\n",
    "                                   axis=1)\n",
    "# nq_geodf.sort_values(['geo2_code','count']) \\\n",
    "#     [(nq_geodf.sort_values(['geo2_code','count']).duplicated('geo2_code',keep=False))]\n",
    "nq_geodf = nq_geodf.sort_values(['geo2_code','count']) \\\n",
    "    [~(nq_geodf.sort_values(['geo2_code','count']).duplicated('geo2_code',keep='last'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(507, 5)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nq_geodf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geo1_code</th>\n",
       "      <th>geo2_code</th>\n",
       "      <th>geo2_name</th>\n",
       "      <th>geo1_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>CABA</td>\n",
       "      <td>CABA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   geo1_code  geo2_code geo2_name geo1_name\n",
       "0          2       2006      CABA      CABA"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipums_geodf[ipums_geodf.geo1_name.str.contains(\"CABA\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geo1_code</th>\n",
       "      <th>geo1_name</th>\n",
       "      <th>geo2_code</th>\n",
       "      <th>geo2_name</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>CABA</td>\n",
       "      <td>999.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    geo1_code geo1_name  geo2_code geo2_name  count\n",
       "11        1.0      CABA      999.0       NaN  30475"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nq_geodf[nq_geodf.geo1_name.str.contains(\"CABA\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a function for fuzzy-joining columns from dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuzzy_join(df1, df2, varname, subset=False, cutoff=90):\n",
    "    '''Returns a dataframe the length of df1, with the matches on the given variable\n",
    "    \n",
    "        Assumes the var is named the same in both dataframes.\n",
    "        \n",
    "        subset is a tuple or list of length 2 whose first element is a string indicating which\n",
    "        variable in df1 has to be equal to which variable in df2 (specified by 2nd element)\n",
    "        '''\n",
    "    #figure out if there is a constraint\n",
    "    if not subset:\n",
    "        #match #1\n",
    "        ratio_matches = df1.astype(str).apply(\n",
    "                lambda d: process.extract(d[varname], \n",
    "                                             df2[varname].astype(str).drop_duplicates(),\n",
    "                                             scorer=fuzz.ratio, limit=2\n",
    "                                            ), axis=1)\n",
    "        #match #2\n",
    "        parti_matches = df1.astype(str).apply(\n",
    "                lambda d: process.extract(d[varname], \n",
    "                                             df2[varname].astype(str).drop_duplicates(),\n",
    "                                             scorer=fuzz.partial_ratio, limit=2\n",
    "                                            ), axis=1)\n",
    "        \n",
    "    else:\n",
    "        #match #1\n",
    "        ratio_matches = df1.astype(str).apply(\n",
    "                lambda d: process.extract(d[varname], \n",
    "                                             df2[varname][df2[subset[1]]==d[subset[0]]].astype(str).drop_duplicates(),\n",
    "                                             scorer=fuzz.ratio, limit=2\n",
    "                                            ), axis=1)\n",
    "        #match #2\n",
    "        parti_matches = df1.astype(str).apply(\n",
    "                lambda d: process.extract(d[varname], \n",
    "                                             df2[varname][df2[subset[1]]==d[subset[0]]].astype(str).drop_duplicates(),\n",
    "                                             scorer=fuzz.partial_ratio, limit=2\n",
    "                                            ), axis=1)    \n",
    "\n",
    "    \n",
    "    # different match cases\n",
    "    #morRatioMatch = ratio_matches.apply(lambda l: (l[0][1]==100)&(l[1][1]==100))\n",
    "    oneRatioMatch = ratio_matches.apply(lambda l: (l[0][1]>=cutoff))#&(l[1][1]<100))\n",
    "    noRatioMatch = ratio_matches.apply(lambda l: (l[0][1]<cutoff))\n",
    "\n",
    "    #morPartiMatch = parti_matches.apply(lambda l: (l[0][1]==100)&(l[1][1]==100))\n",
    "    onePartiMatch = parti_matches.apply(lambda l: (l[0][1]>=cutoff))#&(l[1][1]<100))\n",
    "    noPartiMatch = parti_matches.apply(lambda l: (l[0][1]<cutoff))\n",
    "    \n",
    "    # pick out what's better\n",
    "    matches = pd.Series([(np.nan,np.nan,np.nan)]*len(df1),index=df1.index)\n",
    "    matches.loc[oneRatioMatch] = ratio_matches.loc[oneRatioMatch].apply(lambda l: l[0])\n",
    "    matches.loc[(noRatioMatch&onePartiMatch)] = parti_matches.loc[(noRatioMatch&onePartiMatch)]\\\n",
    "        .apply(lambda l: l[0])\n",
    "    matches.loc[(noRatioMatch&noPartiMatch)] = parti_matches.loc[(noRatioMatch&noPartiMatch)]\\\n",
    "        .apply(lambda l: l[0])\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    df['name'] = matches.apply(lambda l: l[0])\n",
    "    df['score'] = matches.apply(lambda l: l[1])\n",
    "    df['index'] = matches.apply(lambda l: l[2])\n",
    "    df['parti_matches'] = parti_matches\n",
    "    df['ratio_matches'] = ratio_matches\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the new tool!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual fixes, as found necessary in the next step...\n",
    "Might want to outsource these into external function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "nq_geodf.loc[nq_geodf.geo2_code==999, 'geo2_name'] = \"CABA\"\n",
    "\n",
    "ipums_geodf.loc[ipums_geodf.geo1_name.str.contains(\"Buenos Aires province\"),\n",
    "             'geo1_name'] = \"Buenos Aires\"\n",
    "\n",
    "ipums_geodf.loc[ipums_geodf.geo2_name.str.contains(\"Puan\"),\n",
    "                'geo2_name'] = \"Puán\"\n",
    "ipums_geodf.loc[(ipums_geodf.geo2_name.str.contains(\"General San Martín\"))\\\n",
    "                &(ipums_geodf.geo1_name==\"Buenos Aires\"),\n",
    "                'geo2_name'] = \"Ciudad Libertador San Martín\"\n",
    "ipums_geodf.loc[(ipums_geodf.geo2_name.str.contains(\"La Capital\"))\\\n",
    "                &(ipums_geodf.geo1_name==\"San Luis\"),\n",
    "                'geo2_name'] = \"Juan Martín de Pueyrredón\"\n",
    "ipums_geodf.loc[(ipums_geodf.geo2_name==\"Maipú\")\\\n",
    "                &(ipums_geodf.geo2_code==6050),\n",
    "                'geo2_name'] = \"Marcos Paz\"\n",
    "\n",
    "\n",
    "\n",
    "ipums_geodf.loc[(ipums_geodf.geo2_name.str.contains(\"Chascomus\")),\n",
    "                'geo2_name'] = \"Chascomús\"\n",
    "ipums_geodf.loc[(ipums_geodf.geo2_name.str.contains(\"Jose C. Paz\")),\n",
    "                'geo2_name'] = \"José C. Paz\"\n",
    "# nq_geodf.loc[(nq_geodf.geo2_name.str.contains(\"Adolfo Gonzales Chaves\")),\n",
    "#                 'geo2_name'] = \"Adolfo González Chaves\"\n",
    "nq_geodf.loc[(nq_geodf.geo2_name.str.contains(\"Paso de Indios\"))\\\n",
    "                &(nq_geodf.geo1_name==\"Chubut\"),\n",
    "                'geo2_name'] = \"Paso de los Indios\"\n",
    "nq_geodf.loc[(nq_geodf.geo2_name.str.contains(\"Coronel de Marina Leonardo Rosales\"))\\\n",
    "                &(nq_geodf.geo1_name==\"Buenos Aires\"),\n",
    "                'geo2_name'] = \"Coronel de Marine L. Rosales\"\n",
    "ipums_geodf.loc[(ipums_geodf.geo2_name.str.contains(\"Veinticinco de Mayo\"))\\\n",
    "                &(ipums_geodf.geo1_name==\"Buenos Aires\"),\n",
    "                'geo2_name'] = \"25 de Mayo\"\n",
    "nq_geodf.loc[(nq_geodf.geo2_name.str.contains(\"Pueyrredón\"))\\\n",
    "                &(nq_geodf.geo1_name==\"Buenos Aires\"),\n",
    "                'geo2_name'] = \"General Pueyrredón\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fuzzy joining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nq_geodf[['geo1_match_name','geo1_match_score','geo1_match_index']] \\\n",
    "= fuzzy_join(nq_geodf, ipums_geodf, 'geo1_name')[['name','score','index']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "nq_geodf[['geo2_match_name','geo2_match_score','geo2_match_index']] \\\n",
    "= fuzzy_join(nq_geodf, ipums_geodf, 'geo2_name', \n",
    "             subset=['geo1_match_name','geo1_name']\n",
    "            )[['name','score','index']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Double-check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = nq_geodf.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is still an issue??**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geo1_code</th>\n",
       "      <th>geo2_code</th>\n",
       "      <th>geo1_name</th>\n",
       "      <th>geo1_match_name</th>\n",
       "      <th>geo2_name</th>\n",
       "      <th>geo2_match_name</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [geo1_code, geo2_code, geo1_name, geo1_match_name, geo2_name, geo2_match_name, count]\n",
       "Index: []"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp[tmp.duplicated('geo2_code', keep=False)].sort_values('geo2_code')\\\n",
    "[[\"geo1_code\",\"geo2_code\",\n",
    "  \"geo1_name\",\"geo1_match_name\",\n",
    "  \"geo2_name\",\"geo2_match_name\",\n",
    "  \"count\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Success! This can be the geo-df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "nq_geodf = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geo1_name</th>\n",
       "      <th>geo1_code</th>\n",
       "      <th>geo2_name</th>\n",
       "      <th>geo2_code</th>\n",
       "      <th>geo2_match_name</th>\n",
       "      <th>geo2_match_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [geo1_name, geo1_code, geo2_name, geo2_code, geo2_match_name, geo2_match_score]\n",
       "Index: []"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nq_geodf[(nq_geodf.geo2_match_score<71)][['geo1_name',\n",
    "                                          'geo1_code',\n",
    "#                                         'geo1_match_name',\n",
    "                                        'geo2_name',\n",
    "                                        'geo2_code',\n",
    "                                        'geo2_match_name',\n",
    "                                        'geo2_match_score'\n",
    "                                       ]\n",
    "                                      ].sort_values('geo1_name'\n",
    "                                      )#.to_csv(\"./faulty_matches.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geo1_name</th>\n",
       "      <th>geo2_name</th>\n",
       "      <th>geo2_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Buenos Aires</td>\n",
       "      <td>Marcos Paz</td>\n",
       "      <td>6050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       geo1_name   geo2_name  geo2_code\n",
       "80  Buenos Aires  Marcos Paz       6050"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipums_geodf[[\"geo1_name\",\"geo2_name\",\"geo2_code\"]\n",
    "           ][ipums_geodf.geo2_name.str.contains(\"Marcos Paz\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This currently requires manual intervention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "has_ipums_geo = nq_geodf.geo2_match_score>70 #&nq_geodf.geo1_match_index.notna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "507"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(has_ipums_geo)\n",
    "len(nq_geodf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attaching code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "nq_geodf['IPUMS_geo2_code'] = np.nan\n",
    "\n",
    "nq_geodf.loc[has_ipums_geo,'IPUMS_geo2_code'] = nq_geodf[has_ipums_geo]\\\n",
    "                            .geo2_match_index\\\n",
    "                            .astype(int)\\\n",
    "                            .apply(\n",
    "                                lambda i: ipums_geodf.loc[i,'geo2_code']\n",
    "                            .astype(int)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to replace each nq_geo2 with the _code_ for the corresponding census geography.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the municipio-centroids, and hopefully attach them here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo2_centroids = pd.read_csv('../../../Data/'+country+'/geography/'+country+'_geo2_centroids.csv', encoding='latin1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge centroids onto NQ geometries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "nq_geodf_merged = nq_geodf.merge(geo2_centroids[['ADMIN_NAME','Y','X','IPUM'+year]], \n",
    "               left_on='IPUMS_geo2_code',\n",
    "               right_on=\"IPUM\"+year,\n",
    "               how='left'\n",
    "              ).drop('IPUM'+year, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge NQ geometries onto NQ data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "panel_geo = netquest.merge(nq_geodf_merged[['X','Y','geo2_code']],\n",
    "               left_on=geo2_nq,\n",
    "               right_on='geo2_code',\n",
    "               how='left'\n",
    "              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing out\n",
    "Filenames should be stored externally for each country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "panel_geo.shape[0]==netquest.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "panel_geo.to_csv('../../../Data/'+country+'/panel/'+country+'_netquest-panel_geo.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the same for census: attach geographies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_geo = census.merge(geo2_centroids[['ADMIN_NAME','X',\"Y\",'IPUM'+year]],\n",
    "                          left_on = geo2_ipums,\n",
    "                          right_on='IPUM'+year,\n",
    "                          how='left'\n",
    "                         ).drop('IPUM'+year,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census_geo.shape[0]==census.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_geo.to_csv('../../../Data/'+country+'/sample/'+country+'_ipums-census_geo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
