---
title: "sample-matching_IPUMS-NQ_CO, wave 16 'Blitz'"
author: "Maita Schade"
date: "Aug 15, 2019"
output: html_notebook
---


run: *Ctrl+Shift+Enter*. 
New chunk: *Ctrl+Alt+I*.
*Ctrl+Shift+K* to preview the HTML file.

Make sure we're dealing with a clear space:
```{r}
rm(list = ls(all = TRUE))
```

```{r}
country = "CO"
```


If using previously loaded census data, load here:
```{r}
load(paste0(country,"_data_loaded.RData"))
```

```{r}
strat1 = "GEO1_CO2005"
strat2 = "URBAN"
NQ_id  = "gp_codigo"
wave = 16
filedate = "190814"

wd<-paste0("C:/Users/schadem/Box Sync/LAPOP Shared/working documents/maita/Coordination/IDB Online/Matching process/Data/",country)
```


```{r}
library('MatchIt')
library('openxlsx')
library('labelled')

require(plyr)
require(reshape2)
require(stringr)
```

Load required data
```{r}
# census<- read.csv(
#   paste0('C:/Users/schadem/Box Sync/LAPOP Shared/working documents/maita/Coordination/IDB Online/Matching process/Data/',country,'/sample/',country,'_ipums-census_geo.csv')
#  )
# 
# netquest <- read.csv(
#   paste0("C:/Users/schadem/Box Sync/LAPOP Shared/working documents/maita/Coordination/IDB Online/Matching process/Data/",
#   country,
#   "/panel/", country, "_netquest-panel_geo.csv")
# )
# save.image(paste0(country,"_data_loaded.RData"))
```


The selected target, and the recorded responses:
```{r}
# Printing what invites are considered
cat(paste0("Included invite files: \n"))

# Reading in invite files from all waves
waves <- lapply(list.files(path=paste0(wd,"/panel/"), pattern = "wave"), function (x){
  cat(paste0("    ",x,"\n"))
## We make sure the individual waves have distinguishable names by attaching suffixes
  
  df<-read.csv(paste0(wd, "/panel/",x),as.is = T) #c(NQ_id,"SERIAL","PERNUM"))
  df[names(df)[grep(NQ_id,names(df))]]<-sapply(df[names(df)[grep(NQ_id,names(df))]], tolower)
  nwave=as.numeric(str_match(x, "wave(\\d+)")[2])
  suffix=paste0(".",nwave+0:(ncol(df)-5))
  names(df)[grep(NQ_id,names(df))] <- paste0(NQ_id,suffix)
  return(df)
 }
)
```
```{r}

# Creating a single distinguishable sample ID for each individual target record
# make sure, if ever reusing this code, that SERIAL and PERNUM are not longer than anticipated
waves <- lapply(waves,function(x){
  x$SAMPCT <- rep(1, nrow(x))
  x$SAMPID <- paste0(
    sprintf('%010.0f',x$SERIAL),
    sprintf('%03.0f',x$PERNUM)
  )
## Individual person records that were drawn multiple times due to weighting will have a higher sample count
  for (i in unique(x[duplicated(x$SAMPID),'SAMPID'])){
    x[x$SAMPID==i,'SAMPCT']<- 1:length(x[x$SAMPID==i,'SAMPCT'])
  }
  return(x)
  }
  #x[NQ_id] <- sapply(x[NQ_id], tolower)
)

# The target is a table of target records, with selected panelist IDs for each wave
target <- Reduce(function(dtf1, dtf2) {merge(dtf1, dtf2, 
                                             by = c("SAMPID","SAMPCT","SERIAL","PERNUM"), 
                                             all.x = TRUE)},
                 waves)
target <- target[names(target)[-grep("targetId|X",names(target))]]

# "selected" is a long list of all NQ panelists selected from our end
selected_wide <- Reduce(function(dtf1, dtf2) {merge(dtf1, dtf2, 
                                             by = c("SAMPID","SAMPCT","SERIAL","PERNUM"), 
                                             all.x = TRUE, all.y = TRUE)},
                 waves)
selected <- selected_wide[names(selected_wide)[-grep("targetId|X",names(selected_wide))]]
selected <- melt(data = selected,measure.vars = c(grep(NQ_id,names(selected))))
names(selected)<-c("SAMPID",   "SAMPCT",   "SERIAL",   "PERNUM",   "variable", NQ_id)
selected<-selected[!is.na(selected[[NQ_id]]),]
selected$wave <- as.integer(regmatches(selected$variable, 
                                       regexpr("\\.\\K\\d+$",selected$variable,perl=TRUE)
                                       )
                            )
```

```{r}
table(target$SAMPID)[table(target$SAMPID)>1] #check this! if there are duplicates I need to get clever
```
```{r}
# "responded" are just all the IDs NQ has recorded responding to our survey
responded <- read.xlsx(
paste0("C:/Users/schadem/Box Sync/LAPOP Shared/working documents/maita/Coordination/IDB Online/Matching process/Data/",
country,
"/panel/", country,"_complete_",filedate,".xlsx")
)
names(responded) <- c(NQ_id)
responded[[NQ_id]]<-sapply(responded[[NQ_id]], tolower)

#... for identifying how many targets have been hit, attach to each respondent its unique SAMPID
responded <- join(x=responded,y=selected, by=NQ_id)
responded$ID <- paste0(responded$SAMPID,responded$SAMPCT)

table(target$SAMPID)[table(target$SAMPID)>1] #check this! if there are duplicates I need to get clever
responded[responded$SAMPID=="0947330001003"&responded$wave>9,]
# thankfully the duplicates were knocked out earaly so we can proceed.

# Updating selected by wiping out the unused gp_codigos here--
# --if someone responded, we don't invite for that SAMPID for the following waves
apply(responded[responded$wave>=9,c(NQ_id,"SAMPID","wave")],1,
      function(r){
        selected[selected$wave>as.integer(r[["wave"]]) & selected$SAMPID==r[["SAMPID"]],NQ_id] <- NA
        assign('selected',selected,pos=.GlobalEnv)
        return(invisible())
      }
      )
selected[is.na(selected$gp_codigo)&selected$wave>9,]
```

```{r}
# Accounting for intentional "duplicates" due to weights by counting each ID in target and responses:
nsamp_resp <- table(responded$SAMPID) 
nsamp_targ <- table(target$SAMPID)

dupes <- sum(sapply(names(nsamp_resp), function(x){
  if (nsamp_resp[x]>nsamp_targ[x]){
    nsamp_resp[x]-nsamp_targ[x]
    } 
  else {0}
  }))

legit <- nrow(responded)-dupes

cat(paste0("\nDuplicates in ", country, ": ", dupes,"\n"))
cat(paste0("\nLegit responses: ", legit))
```
Respondents that were not invited:
```{r}
cat(responded[is.na(responded$SAMPID),][[NQ_id]])
```


Prune panel to exclude invited
```{r}
netquest <- netquest[! (netquest[[NQ_id]] %in% selected[[NQ_id]]),]
```

Prune target to exclude filled slots
```{r}
# create list of respondents in wide sample id format
selected_resp <- selected[(selected[[NQ_id]] %in% responded[[NQ_id]]),] #those that were invited and actually responded
resp_wide <- reshape(selected_resp[-grep("wave",names(selected_resp))], idvar = c("SAMPID","SAMPCT","SERIAL","PERNUM"), timevar = "variable", direction = "wide")
names(resp_wide)<-names(target[1:length(names(resp_wide))])
# count desired and achieved occurrence of each sample ID (filling in zeros) 
nsamp_targ <- table(target$SAMPID)      #counts for each SAMPID in target
nsamp_resp <- table(resp_wide$SAMPID)   #counts for each SAMPID in actual responses
nsamp_resp[target$SAMPID[!target$SAMPID%in%resp_wide$SAMPID]]<-0  #if SAMPID wasn't collected at all yet, resp. = 0

# I want the SAMPIDs that have fewer occurrences in the response set than in the target.
target_pruned <- target[nsamp_resp[target$SAMPID]<nsamp_targ[target$SAMPID],]
```


Double-check any sample IDs that have a response already but are being re-invited--make sure they are desired more than once.
```{r}
print(sum(target_pruned$SAMPID%in%resp_wide$SAMPID))
target_pruned[target_pruned$SAMPID%in%resp_wide$SAMPID,]
cat(nsamp_resp[unique(target_pruned[target_pruned$SAMPID%in%resp_wide$SAMPID,]$SAMPID)])
```

Cutting just the bits of the census we need going forward:
```{r}
print(dim(target_pruned))
tmp <- join(target_pruned[c('SERIAL','PERNUM')], census, by=c('SERIAL','PERNUM'))
print(dim(tmp))
census <- tmp
```


We have to recode the various characteristics we have at our disposal.
```{r}
matching.vars <- c('gend', 
                   'age', 
                   'ed', 
                   'ed_hhh', 
                   'emp', 
                   'emp_hhh', 
                   'child',
                   'marst',
                   'pern',
                   'hhtype',
                   'hhh',
                   'X',
                   'Y'
                   )
#Gender:          is fine.
census$gend <- census$SEX
netquest$gend <- netquest$p_sexo

#Age:          is fine, need to filter these to make sure we exclude too young respondents.
census$age <- mapvalues(census$AGE, from=c(999), to=c(NA))
netquest$age <- netquest$panelistAge
netquest$age[netquest$panelistAge>100] <- 100

#Education:    EDUCCL partially matches CL_education_level; the census doesn't count postgrad so have to collapse in panel
census$ed[census$EDUCCO<=250 | census$EDUCCO==270] <- 1
census$ed[census$EDUCCO==260] <- 2
census$ed[census$EDUCCO>=320 & census$EDUCCO<=380] <- 3
census$ed[census$EDUCCO>=390 & census$EDUCCO<=439] <- 4
census$ed[census$EDUCCO>=440 & census$EDUCCO<=449] <- 5
census$ed[census$EDUCCO>=500 & census$EDUCCO<=590] <- 6

netquest$ed <- as.integer(netquest$CO_education_level)
#    Need head of household, as well.
census$ed_hhh[census$EDUCCO_HEAD<=250 | census$EDUCCO_HEAD==270] <- 1
census$ed_hhh[census$EDUCCO_HEAD==260] <- 2
census$ed_hhh[census$EDUCCO_HEAD>=320 & census$EDUCCO_HEAD<=380] <- 3
census$ed_hhh[census$EDUCCO_HEAD>=390 & census$EDUCCO_HEAD<=439] <- 4
census$ed_hhh[census$EDUCCO_HEAD>=440 & census$EDUCCO_HEAD<=449] <- 5
census$ed_hhh[census$EDUCCO_HEAD>=500 & census$EDUCCO_HEAD<=590] <- 6

netquest$ed_hhh <- as.integer(netquest$CO_education_level_hhousehold)

#Employment. Reconsider ordering.
census$emp <- mapvalues(census$CO2005A_EMPSTAT,
        from=c(  1,  5,  3,  4,  8,  7,  6,  9, 98, 99),
        to=  c(  1,  4,  6,  5,  8,  9,  3, NA, NA, NA))
census$emp[census$CLASSWK==2]<- 2
netquest$emp <- mapvalues(netquest$CO_laboral_situation,
       from=c(1,2,3,4,5,6,7,8,9),
       to=  c(1,2,4,6,5,8,8,9,3))


#  Employment of head of household: There's a question of how to map "living on rents" (341), 390 "inactive"
census$emp_hhh <- mapvalues(census$CO2005A_EMPSTAT_HEAD,
        from=c(  1,  5,  3,  4,  8,  7,  6,  9, 98, 99),
        to=  c(  1,  4,  6,  5,  8,  9,  3, NA, NA, NA))
census$emp_hhh[census$CLASSWK_HEAD==2]<- 2
netquest$emp_hhh <- mapvalues(netquest$CO_laboral_situation_hhousehold,
       from=c(1,2,3,4,5,6,7,8,9),
       to=  c(1,2,4,6,5,8,8,9,3))

#Children
census$child<-census$NCHILD
census$child[census$NCHILD>7] <- 7

netquest$child <- netquest$number_P3
netquest$child[netquest$P3==2] <- 0

#Marital status: need P1 from Netquest!
census$marst <- mapvalues(census$MARST,
                          from=c(1,2,3,4,9),
                          to  =c(1,4,2,3,NA)
                          )

netquest$marst <- mapvalues(netquest$P1,
                          from=c(1,2,3,4),
                          to  =c(1,4,2,3)
                          )

#number of persons in household
census$pern <- census$PERSONS
netquest$pern <- netquest$P2

#type of household
census$hhtype <- mapvalues(census$HHTYPE,
                          from=c(1,5,6,7,8,2,3,4,11,99, 0),
                          to  =c(1,5,5,6,6,2,4,3, 0, 0,NA)
                          )

netquest$hhtype <- mapvalues(netquest$P8,
                          from=c(1,2,3,4,5,6,7,99),
                          to  =c(1,5,6,2,4,3,5, 0)
                          )

#head of household?
census$hhh[census$RELATE>1] <- 2
census$hhh[census$RELATE==1] <- 1

netquest$hhh <- mapvalues(netquest$P12,
                          from=c(1,2,3),
                          to  =c(1,2,1)
                          )
```


Give ID to both datasets, so we can go back to IDs when necessary
```{r}
census$id <- seq(dim(census)[1])
netquest$id <- seq(dim(netquest)[1])
```


Create the sample and panel from this:


If we do some non-numeric matching, we'd want to adjust the labels/levels.
```{r}
panel <- to_factor(netquest[append(matching.vars, c('id'))],
                   drop_unused_labels = TRUE)
panel['Fakeid'] <- netquest[[NQ_id]]
panel <- panel[panel$age>17,]

panel <- na.omit(panel)     
```

ADJUST FOR COUNTRY!
There are too many (> 160k) NAs in emplayment, from the "other" category; need to decide what to do with these.
```{r}
census.proc <- to_factor(census[append(matching.vars,c(
                                          strat2,
                                          'PERWT',
                                          strat1,'id', 'SERIAL', 'PERNUM'))], drop_unused_labels = TRUE)

census.proc <- census.proc[census.proc$age>17,]

census.proc <- na.omit(census.proc)
census.proc <- census.proc[order(census.proc[strat1],census.proc[strat2]),]

```


Re-load the target with census info
```{r}
target_pruned <- census.proc
target_pruned <- target_pruned[!names(target_pruned) %in% c('SERIAL','PERNUM')]
target_pruned['Fakeid'] <- as.integer(rep(999999, length(target_pruned$age)))
```



Add a treatment into it:
```{r}
panel['treat'] <- rep(0,length(panel$age))
target_pruned['treat'] <- rep(1,length(target_pruned$age))
```


Now join this data together:
```{r}
# add a level to the alldata fakeid to accommodate the target
levels(panel$Fakeid) <- c(levels(panel$Fakeid),999999)
alldata<-rbind(panel,target_pruned[names(panel)])

#jointId will be the sequence number in the joint dataframe -- MAY NOT NEED THIS?
alldata$jointId <- seq(dim(alldata)[1])
rownames(alldata) <- alldata$jointId

```

Divide target sample into age quantiles (in this case, deciles) and add that to the data:
```{r}
age_q <- quantile(census$age,prob = seq(0,1,0.1))
alldata['age_group'] <- as.integer(cut(alldata$age,breaks = age_q, include.lowest = TRUE))
alldata$age_group[is.na(alldata$age_group)] <- 10
```

#for the methods that require numeric approximation
```{r}
alldata_num<-data.frame(lapply(alldata, as.numeric))
```

Now the matching begins. This is using the MatchIt package as we are used to...
```{r}
matching.form <- as.formula(paste0("treat ~ ", paste(matching.vars, collapse=' + ')))
```


We'll have to repeat this process (at least for everything except PS), since the memory can't deal with all of this. 
* start empty dataframe initialized with target IDs
* make a copy of the data to alter
* for each i in range:
  + run the matching
  + store the matched IDs
  + store some overall metrics about the match
  + reduce the panel data
* return the match objects

```{r}
matchRatio <- function(data, metric, n, exact = c()){
  
  # assign the dataframe to hold the matching results
  df <- data.frame(matrix(ncol=1, nrow=sum(data$treat==1)))
  names(df) <- c("targetId")
  df$targetId <- data$id[data$treat==1]
  
  # assign the object to hold all the matching information
  matches <- vector("list",n)
  
  # make a copy of the passed-in data
  data.copy <- data.frame(data)
  
  
  # loop over the number of respondents per target
  # if there are issues, can I relax the age groups?
  for(i in 1:n){
    print(paste('i = ',to_character(i)))
    m <- matchit(matching.form, 
                 data = data.copy, exact=exact, method = "nearest", distance = metric)
    
    try({matches[[i]] <- m
        targetids <- data.copy[row.names(m$match.matrix), "id"]
        panelids <- as.data.frame(data.copy[m$match.matrix,"id"])
        names(panelids)<-c("panelId")
        panelids['targetId']<-targetids
        df <- merge(x=df, y=panelids, by="targetId", all.x = TRUE, suffixes=c("",to_character(i)))
        } #... maybe merge instead might be safer?
    )
    
    controls <- match.data(m, group='control')
    data.copy <- data.copy[!data.copy$jointId %in% controls$jointId,] # not relying on rownames
    
  }
  return(list("ids"=df, "matches"=matches))
}
```

```{r}
n <- 5
matches.cem_mah = matchRatio(alldata_num, "mahalanobis", n, exact = c("age_group","gend"))
```


Save the id's of the matches to a file, so I don't lose them--just in case
```{r}
tmp <- matches.cem_mah$ids

# attaching NQ panel code
for (i in c(1:n)){
  s <- ifelse(i>1, i,"")
  print(i)
  print(paste0("panelId",s))
  
  tmp[paste0(NQ_id,i)] <- merge(x = matches.cem_mah$ids, 
                    y = alldata[alldata$treat==0, c("Fakeid",'id')], 
                    by.x = paste0("panelId",s), 
                    by.y = "id")[["Fakeid"]]
  }


# attaching census identification, just in case!
tmp[c("SERIAL","PERNUM")] <- merge(x = matches.cem_mah$ids,
                                   y = census[c("SERIAL","PERNUM","id")],
                                   by.x = 'targetId',
                                   by.y = 'id')[c("SERIAL","PERNUM")]

write.csv(x=tmp[c(c("targetId"),paste0(NQ_id,c(1:n)), c("SERIAL","PERNUM"))], file=paste0("C:/Users/schadem/Box Sync/LAPOP Shared/working documents/maita/Coordination/IDB Online/Matching process/Data/",country,"/panel/",country,"_selected_wave",wave,"_",filedate,".csv"))
filedate
```

