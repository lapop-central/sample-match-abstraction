---
title: "sample-matching_IPUMS-NQ_AR, wave 17 'Catch-up'"
author: "Maita Schade"
date: "Aug 26, 2019"
output: html_notebook
---


run: *Ctrl+Shift+Enter*. 
New chunk: *Ctrl+Alt+I*.
*Ctrl+Shift+K* to preview the HTML file.

Make sure we're dealing with a clear space:
```{r}
rm(list = ls(all = TRUE))
```

Set the space up
```{r}
country = "AR"
```

If using previously loaded census data, load here:
```{r}
load(paste0(country,"_data_loaded.RData"))
```

```{r}
strat1 = "GEO1_AR2010"
strat2 = "URBAN"
NQ_id  = "p_codigo"
wave = 17
filedate = "190826"

wd<-paste0("C:/Users/schadem/Box Sync/LAPOP Shared/working documents/maita/Coordination/IDB Online/Matching process/Data/",country)
```


```{r}
library('MatchIt')
library('openxlsx')
library('labelled')

require(plyr)
require(reshape2)
require(stringr)
```


Load required data
```{r}
# census<- read.csv(
#   paste0('C:/Users/schadem/Box Sync/LAPOP Shared/working documents/maita/Coordination/IDB Online/Matching process/Data/',country,'/sample/',country,'_ipums-census_geo.csv')
#  )
# 
# netquest <- read.csv(
#   paste0("C:/Users/schadem/Box Sync/LAPOP Shared/working documents/maita/Coordination/IDB Online/Matching process/Data/",
#   country,
#   "/panel/", country, "_netquest-panel_geo.csv")
# )
# save.image(paste0(country,"_data_loaded.RData"))
```



The selected target, and the recorded responses:
```{r}
# Printing what invites are considered
cat(paste0("Included invite files: \n"))

# Reading in invite files from all waves
waves <- lapply(list.files(path=paste0(wd,"/panel/"), pattern = "wave"), function (x){
  cat(paste0("    ",x,"\n"))
## We make sure the individual waves have distinguishable names by attaching suffixes
  
  df<-read.csv(paste0(wd, "/panel/",x),as.is = T) #c(NQ_id,"SERIAL","PERNUM"))
  df[names(df)[grep(NQ_id,names(df))]]<-sapply(df[names(df)[grep(NQ_id,names(df))]], tolower)
  nwave=as.numeric(str_match(x, "wave(\\d+)")[2])
  suffix=paste0(".",nwave+0:(ncol(df)-5))
  names(df)[grep(NQ_id,names(df))] <- paste0(NQ_id,suffix)
  return(df)
 }
)
```

```{r}
# Creating a single distinguishable sample ID for each individual target record
# make sure, if ever reusing this code, that SERIAL and PERNUM are not longer than anticipated
waves <- lapply(waves,function(x){
  x$SAMPCT <- rep(1, nrow(x))
  x$SAMPID <- paste0(
    sprintf('%010.0f',x$SERIAL),
    sprintf('%03.0f',x$PERNUM)
  )
## Individual person records that were drawn multiple times due to weighting will have a higher sample count
  for (i in unique(x[duplicated(x$SAMPID),'SAMPID'])){
    x[x$SAMPID==i,'SAMPCT']<- 1:length(x[x$SAMPID==i,'SAMPCT'])
  }
  return(x)
  }
  #x[NQ_id] <- sapply(x[NQ_id], tolower)
)

# The target is a table of target records, with selected panelist IDs for each wave
target <- Reduce(function(dtf1, dtf2) {merge(dtf1, dtf2, 
                                             by = c("SAMPID","SAMPCT","SERIAL","PERNUM"), 
                                             all.x = TRUE)},
                 waves)
target <- target[names(target)[-grep("targetId|X",names(target))]]

# "selected" is a long list of all NQ panelists selected from our end
selected_wide <- Reduce(function(dtf1, dtf2) {merge(dtf1, dtf2, 
                                             by = c("SAMPID","SAMPCT","SERIAL","PERNUM"), 
                                             all.x = TRUE, all.y = TRUE)},
                 waves)
selected <- selected_wide[names(selected_wide)[-grep("targetId|X",names(selected_wide))]]
selected <- melt(data = selected,measure.vars = c(grep(NQ_id,names(selected))))
names(selected)<-c("SAMPID",   "SAMPCT",   "SERIAL",   "PERNUM",   "variable", NQ_id)
selected<-selected[!is.na(selected[[NQ_id]]),]
selected$wave <- as.integer(regmatches(selected$variable, 
                                       regexpr("\\.\\K\\d+$",selected$variable,perl=TRUE)
                                       )
                            )
```
```{r}
table(target$SAMPID)[table(target$SAMPID)>1] #check this! if there are duplicates I need to get clever
```


```{r}
# "responded" are just all the IDs NQ has recorded responding to our survey
responded <- read.xlsx(
paste0("C:/Users/schadem/Box Sync/LAPOP Shared/working documents/maita/Coordination/IDB Online/Matching process/Data/",
country,
"/panel/", country,"_complete_",filedate,".xlsx"),
colNames = FALSE
)
names(responded) <- c(NQ_id)
responded[[NQ_id]]<-sapply(responded[[NQ_id]], tolower)
#... for identifying how many targets have been hit, attach to each respondent its unique SAMPID
responded <- join(x=responded,y=selected, by=NQ_id)
responded <- responded[!duplicated(responded[[NQ_id]],fromLast = TRUE),]
responded$ID <- paste0(responded$SAMPID,responded$SAMPCT)

# table(target$SAMPID)[table(target$SAMPID)>1] #check this! if there are duplicates I need to get clever
# responded[responded$SAMPID=="0947330001003"&responded$wave>9,]
# # thankfully the duplicates were knocked out earaly so we can proceed.
nrow(responded)
# Updating selected by wiping out the unused gp_codigos here--
# --if someone responded, we don't invite for that SAMPID for the following waves
#apply(responded[responded$wave>=10&responded$wave<16,c(NQ_id,"SAMPID","wave")],1,
      # function(r){
      #   selected[selected$wave>as.integer(r[["wave"]]) & selected$SAMPID==r[["SAMPID"]],NQ_id]<-NA
      #   # selected[selected$wave>as.integer(r[["wave"]]) & selected$SAMPID==r[["SAMPID"]],NQ_id] <- 99
      #   # assign('selected',selected,pos=.GlobalEnv)
      #   return(invisible())
      # }
      # )

#selected[is.na(selected[[NQ_id]]),]
```

```{r}
# Accounting for intentional "duplicates" due to weights by counting each ID in target and responses:
nsamp_resp <- table(responded$SAMPID) 
nsamp_targ <- table(target$SAMPID)

dupes <- sum(sapply(names(nsamp_resp), function(x){
  if (nsamp_resp[x]>nsamp_targ[x]){
    nsamp_resp[x]-nsamp_targ[x]
    } 
  else {0}
  }))

legit <- nrow(responded)-dupes

cat(paste0("\nDuplicates in ", country, ": ", dupes,"\n"))
cat(paste0("\nLegit responses: ", legit))
```
Respondents that were not invited:
```{r}
cat(responded[is.na(responded$SAMPID),][[NQ_id]])
```

Prune panel to exclude invited
```{r}
netquest <- netquest[! (netquest[[NQ_id]] %in% selected[[NQ_id]]),]
```

Prune target to exclude filled slots 
```{r}
# create list of respondents in wide sample id format
selected_resp <- selected[(selected[[NQ_id]] %in% responded[[NQ_id]]),] #those that were invited and actually responded
resp_wide <- reshape(selected_resp[-grep("wave",names(selected_resp))], idvar = c("SAMPID","SAMPCT","SERIAL","PERNUM"), timevar = "variable", direction = "wide")
names(resp_wide)<-names(target[1:length(names(resp_wide))])
# count desired and achieved occurrence of each sample ID (filling in zeros) 
nsamp_targ <- table(target$SAMPID)      #counts for each SAMPID in target
nsamp_resp <- table(resp_wide$SAMPID)   #counts for each SAMPID in actual responses
nsamp_resp[target$SAMPID[!target$SAMPID%in%resp_wide$SAMPID]]<-0  #if SAMPID wasn't collected at all yet, resp. = 0

# I want the SAMPIDs that have fewer occurrences in the response set than in the target.
target_pruned <- target[nsamp_resp[target$SAMPID]<nsamp_targ[target$SAMPID],]
dim(selected_resp)
dim(responded)
dim(resp_wide)
dim(target_pruned)
```


Double-check any sample IDs that have a response already but are being re-invited--make sure they are desired more than once.
```{r}
print(sum(target_pruned$SAMPID%in%resp_wide$SAMPID))
target_pruned[target_pruned$SAMPID%in%resp_wide$SAMPID,]
cat(nsamp_resp[unique(target_pruned[target_pruned$SAMPID%in%resp_wide$SAMPID,]$SAMPID)])
```

Cutting just the bits of the census we need going forward:
```{r}
print(dim(target_pruned))
tmp <- join(target_pruned[c('SERIAL','PERNUM')], census, by=c('SERIAL','PERNUM'))
print(dim(tmp))
census <- tmp
```





We have to recode the various characteristics we have at our disposal.
```{r}
matching.vars <- c('gend', 
                   'age', 
                   'bath',
                   'ed',  
                   'emp', 
                   'pern',
                   'hhh',
                   'X',
                   'Y'
                   )

# Gender:          is fine.
census$gend <- census$SEX
netquest$gend <- netquest$p_sexo

#Age:          is fine, need to filter these to make sure we exclude too young respondents.
census$age <- mapvalues(census$AGE, from=c(999), to=c(NA))
netquest$age <- netquest$panelistAge
netquest$age[netquest$panelistAge>100] <- 100

#Education:    EDUCCL partially matches CL_education_level; the census doesn't count postgrad so have to collapse in panel
#Head of household not included in IPUMS
census$ed <- rep(NA,length=length(census$AR2010A_EDLEV))
census$ed[census$AR2010A_EDLEV%in%c(1)] <- 1
census$ed[census$AR2010A_EDLEV%in%c(2,3)] <- 2
census$ed[census$AR2010A_EDLEV%in%c(4,5)] <- 3
census$ed[census$AR2010A_EDLEV%in%c(6)] <- 4
census$ed[census$AR2010A_EDLEV%in%c(7)] <- 5
census$ed[census$AR2010A_EDLEV%in%c(8)] <- 6

netquest$ed <- mapvalues(netquest$AR_education_level,
                         from=c(1,2,3,4,5,6,7,8,9,10,11),
                         to  =c(1,1,2,2,3,3,4,4,5, 6,NA)
                         )

#Employment. RECONSIDER ORDERING.
census$emp <- rep(NA,length=length(census$EMPSTAT))
census$emp[census$EMPSTAT==1] <- 1 # working
census$emp[census$EMPSTAT==2] <- 2 # unemployed
census$emp[census$EMPSTAT==3] <- 3 # not in workforce

netquest$emp <- mapvalues(netquest$AR_laboral_situation,
       from=c(1,2,3,4,5,6),
       to=  c(1,2,3,3,3,3))

#Have Bath?
census$bath[census$BATH==1] <- 2
census$bath[census$BATH%in%c(3,4)] <- 1

netquest$bath <- netquest$AR_bath_athome

#number of persons in household
census$pern <- census$PERSONS
netquest$pern <- netquest$P2

#head of household?
census$hhh <- rep(NA,length=length(census$RELATE))
census$hhh[census$RELATE>1] <- 2
census$hhh[census$RELATE==1] <- 1

netquest$hhh <- mapvalues(netquest$P12,
                          from=c(1,2,3),
                          to  =c(1,2,1)
                          )
```

Give ID to both datasets, so we can go back to IDs when necessary
```{r}
census$id <- seq(dim(census)[1])
netquest$id <- seq(dim(netquest)[1])
```


If we do some non-numeric matching, we'd want to adjust the labels/levels.
```{r}
panel <- to_factor(netquest[append(matching.vars, c('id'))],
                   drop_unused_labels = TRUE)
panel['Fakeid'] <- netquest[[NQ_id]]
panel <- panel[panel$age>17,]

panel <- na.omit(panel) 
```


ADJUST FOR COUNTRY!
```{r}
census.proc <- to_factor(census[append(matching.vars,
                                       c(strat1,
                                         'PERWT',
                                         'id',
                                         'SERIAL',
                                         'PERNUM'
                                         ))], drop_unused_labels = TRUE)

census.proc <- census.proc[census.proc$age>17,]

census.proc <- na.omit(census.proc)
census.proc <- census.proc[order(census.proc[strat1]),]

```




Re-load the target with census info
```{r}
target_pruned <- census.proc
target_pruned <- target_pruned[!names(target_pruned) %in% c('SERIAL','PERNUM')]
target_pruned['Fakeid'] <- as.integer(rep(999999, length(target_pruned$age)))
```

Add a treatment into it:
```{r}
panel['treat'] <- rep(0,length(panel$age))
target_pruned['treat'] <- rep(1,length(target_pruned$age))
```

Now join this data together:
```{r}
levels(panel$Fakeid) <- c(levels(panel$Fakeid),999999) #to make room for the non-existent Fakeid
alldata<-rbind(panel,target_pruned[names(panel)])

#jointId will be the sequence number in the joint dataframe
alldata$jointId <- seq(dim(alldata)[1])
rownames(alldata) <- alldata$jointId

```

Divide target sample into age quantiles (in this case, deciles) and add that to the data:
```{r}
age_q <- quantile(census$age,prob = seq(0,1,0.1))
alldata['age_group'] <- as.integer(cut(alldata$age,breaks = age_q, include.lowest = TRUE))
alldata$age_group[is.na(alldata$age_group)] <- 10
```

For the methods that require numeric approximation
```{r}
alldata_num<-data.frame(lapply(alldata, as.numeric))
```



Now the matching begins. This is using the MatchIt package as we are used to...
```{r}
matching.form <- as.formula(paste0("treat ~ ", paste(matching.vars, collapse=' + ')))
```


We'll have to repeat this process (at least for everything except PS). 
* start empty dataframe initialized with target IDs
* make a copy of the data to alter
* for each i in range:
  + run the matching
  + store the matched IDs
  + store some overall metrics about the match
  + reduce the panel data
* return the match objects

```{r}
matchRatio <- function(data, metric, n, exact = c()){
  
  # assign the dataframe to hold the matching results
  df <- data.frame(matrix(ncol=1, nrow=sum(data$treat==1)))
  names(df) <- c("targetId")
  df$targetId <- data$id[data$treat==1]
  
  # assign the object to hold all the matching information
  matches <- vector("list",n)
  
  # make a copy of the passed-in data
  data.copy <- data.frame(data)
  
  # loop over the number of respondents per target
  # if there are issues, can I relax the age groups?
  for(i in 1:n){
    print(paste('i = ',to_character(i)))
    m <- matchit(matching.form, 
                 data = data.copy, exact=exact, method = "nearest", distance = metric)
    
    try({matches[[i]] <- m
        targetids <- data.copy[row.names(m$match.matrix), "id"]
        panelids <- as.data.frame(data.copy[m$match.matrix,"id"])
        names(panelids)<-c("panelId")
        panelids['targetId']<-targetids
        df <- merge(x=df, y=panelids, by="targetId", all.x = TRUE, suffixes=c("",to_character(i)))
        } 
    )
    
    controls <- match.data(m, group='control')
    data.copy <- data.copy[!data.copy$jointId %in% controls$jointId,] # not relying on rownames
    
  }
  return(list("ids"=df, "matches"=matches))
}
```

```{r}
n <- 2
matches.cem_mah = matchRatio(alldata_num, "mahalanobis", n, exact = c("age_group","gend"))
```


Save the id's of the matches to a file, so I don't lose them--just in case
```{r}
tmp <- matches.cem_mah$ids

# attaching NQ panel code
for (i in c(1:n)){
  s <- ifelse(i>1, i,"")
  print(i)
  print(paste0("panelId",s))
  
  tmp[paste0(NQ_id,i)] <- merge(x = matches.cem_mah$ids, 
                    y = alldata[alldata$treat==0, c("Fakeid",'id')], 
                    by.x = paste0("panelId",s), 
                    by.y = "id")[["Fakeid"]]
  }


# attaching census identification, just in case!
tmp[c("SERIAL","PERNUM")] <- merge(x = matches.cem_mah$ids,
                                   y = census[c("SERIAL","PERNUM","id")],
                                   by.x = 'targetId',
                                   by.y = 'id')[c("SERIAL","PERNUM")]

write.csv(x=tmp[c(c("targetId"),paste0(NQ_id,c(1:n)), c("SERIAL","PERNUM"))], file=paste0("C:/Users/schadem/Box Sync/LAPOP Shared/working documents/maita/Coordination/IDB Online/Matching process/Data/",country,"/panel/",country,"_selected_wave",wave,"_",filedate,".csv"))
```
```{r}
target_pruned
```


```{r}
sum(tmp[[NQ_id]]%in%selected[[NQ_id]])
dim(target_pruned)
dim(tmp)
dim(responded)
```

