---
title: "match"
author: "Maita Schade"
date: "Aug 26, 2019"
output: html_notebook
---


Given a target sample, recoded panel, and possibly previous invites and completes, this notebook produces a new set of panelists to invite, with flexible number of columns (for larger batches).

Make sure we're dealing with a clear space:
```{r}
rm(list = ls(all = TRUE))
```

Set the space up
```{r}
country <- "AR"
```

```{r}
#strats = ("GEO1_AR2010")
#strat2 = "URBAN"
# wave = 17
# filedate = "190826"
target.date <- "190909"

datadir <- paste0('C:/Users/schadem/Box Sync/LAPOP Shared/working documents/maita/Analysis/Sample match abstraction/Data/',country,'/')

targetfile <- paste0(datadir, "sample/", country, "_target_", target.date, ".csv")

panelfile <- paste0(datadir,'panel/', country, '_netquest_recoded.csv')

recodepath <- paste0("./recode_Netquest_IPUMS_",country, ".csv") #table specifying recodes

# completes
# previous selections
```


```{r}
library('MatchIt')
# library('openxlsx')
# library('labelled')
# 
# require(plyr)
# require(reshape2)
# require(stringr)
```


Load data
```{r}
target <- fread(targetfile, colClasses = c(sampleId="character"))
panel <- fread(panelfile)
```

Are there previous invites? If so, load them.
```{r}
if (length(list.files(path=paste0(datadir,"panel/"), pattern = "wave"))>0){
  print("previous invites found")
  # # Printing what invites are considered
  # cat(paste0("Included invite files: \n"))
  # 
  # # Reading in invite files from all waves
  # waves <- lapply(list.files(path=paste0(wd,"/panel/"), pattern = "wave"), function (x){
  #   cat(paste0("    ",x,"\n"))
  # ## We make sure the individual waves have distinguishable names by attaching suffixes
  #   
  #   df<-read.csv(paste0(wd, "/panel/",x),as.is = T) #c(NQ_id,"SERIAL","PERNUM"))
  #   df[names(df)[grep(NQ_id,names(df))]]<-sapply(df[names(df)[grep(NQ_id,names(df))]], tolower)
  #   nwave=as.numeric(str_match(x, "wave(\\d+)")[2])
  #   suffix=paste0(".",nwave+0:(ncol(df)-5))
  #   names(df)[grep(NQ_id,names(df))] <- paste0(NQ_id,suffix)
  #   return(df)
  #  }
  # )
  
  # # The target is a table of target records, with selected panelist IDs for each wave
  # target <- Reduce(function(dtf1, dtf2) {merge(dtf1, dtf2, 
  #                                              by = c("SAMPID","SAMPCT","SERIAL","PERNUM"), 
  #                                              all.x = TRUE)},
  #                  waves)
  # target <- target[names(target)[-grep("targetId|X",names(target))]]
  
  # "selected" is a long list of all NQ panelists selected from our end
  # selected_wide <- Reduce(function(dtf1, dtf2) {merge(dtf1, dtf2, 
  #                                              by = c("SAMPID","SAMPCT","SERIAL","PERNUM"), 
  #                                              all.x = TRUE, all.y = TRUE)},
  #                  waves)
  # selected <- selected_wide[names(selected_wide)[-grep("targetId|X",names(selected_wide))]]
  # selected <- melt(data = selected,measure.vars = c(grep(NQ_id,names(selected))))
  # names(selected)<-c("SAMPID",   "SAMPCT",   "SERIAL",   "PERNUM",   "variable", NQ_id)
  # selected<-selected[!is.na(selected[[NQ_id]]),]
  # selected$wave <- as.integer(regmatches(selected$variable, 
  #                                        regexpr("\\.\\K\\d+$",selected$variable,perl=TRUE)
  #                                        )
  #                             )
  
  # # Prune panel to exclude invited
  # netquest <- netquest[! (netquest[[NQ_id]] %in% selected[[NQ_id]]),]

} else {wave <- 1}

```

Are there previous completes? If so, load them.
```{r}
if (length(list.files(path=paste0(datadir,"panel/"), pattern = "complete"))>0){
  print("completes found!")

  # # "responded" can be loaded straight from Qualtrics 
  # responded <- read.xlsx(
  # paste0("C:/Users/schadem/Box Sync/LAPOP Shared/working documents/maita/Coordination/IDB Online/Matching process/Data/",
  # country,
  # "/panel/", country,"_complete_",filedate,".xlsx"),
  # colNames = FALSE
  # )
  # names(responded) <- c(NQ_id)
  # responded[[NQ_id]]<-sapply(responded[[NQ_id]], tolower)
  # #... for identifying how many targets have been hit, attach to each respondent its unique SAMPID
  # responded <- join(x=responded,y=selected, by=NQ_id)
  # responded <- responded[!duplicated(responded[[NQ_id]],fromLast = TRUE),]
  # responded$ID <- paste0(responded$SAMPID,responded$SAMPCT)

  # Updating selected by wiping out the unused gp_codigos here--
  # --if someone responded, we don't invite for that SAMPID for the following waves
  #apply(responded[responded$wave>=10&responded$wave<16,c(NQ_id,"SAMPID","wave")],1,
      # function(r){
      #   selected[selected$wave>as.integer(r[["wave"]]) & selected$SAMPID==r[["SAMPID"]],NQ_id]<-NA
      #   # selected[selected$wave>as.integer(r[["wave"]]) & selected$SAMPID==r[["SAMPID"]],NQ_id] <- 99
      #   # assign('selected',selected,pos=.GlobalEnv)
      #   return(invisible())
      # }
      # )

  #selected[is.na(selected[[NQ_id]]),]  
  
  # # Accounting for intentional "duplicates" due to weights by counting each ID in target and responses:
  # nsamp_resp <- table(responded$SAMPID) 
  # nsamp_targ <- table(target$SAMPID)
  # 
  # dupes <- sum(sapply(names(nsamp_resp), function(x){
  #   if (nsamp_resp[x]>nsamp_targ[x]){
  #     nsamp_resp[x]-nsamp_targ[x]
  #     } 
  #   else {0}
  #   }))
  # 
  # legit <- nrow(responded)-dupes
  # 
  # cat(paste0("\nDuplicates in ", country, ": ", dupes,"\n"))
  # cat(paste0("\nLegit responses: ", legit))

  # # Respondents that were not invited?
  # cat(responded[is.na(responded$SAMPID),][[NQ_id]])
  
  # ## Prune target to exclude filled slots
  # # create list of respondents in wide sample id format
  # selected_resp <- selected[(selected[[NQ_id]] %in% responded[[NQ_id]]),] #those that were invited and actually responded
  # resp_wide <- reshape(selected_resp[-grep("wave",names(selected_resp))], idvar = c("SAMPID","SAMPCT","SERIAL","PERNUM"), timevar = "variable", direction = "wide")
  # names(resp_wide)<-names(target[1:length(names(resp_wide))])
  # # count desired and achieved occurrence of each sample ID (filling in zeros) 
  # nsamp_targ <- table(target$SAMPID)      #counts for each SAMPID in target
  # nsamp_resp <- table(resp_wide$SAMPID)   #counts for each SAMPID in actual responses
  # nsamp_resp[target$SAMPID[!target$SAMPID%in%resp_wide$SAMPID]]<-0  #if SAMPID wasn't collected at all yet, resp. = 0
  # 
  # # I want the SAMPIDs that have fewer occurrences in the response set than in the target.
  # target_pruned <- target[nsamp_resp[target$SAMPID]<nsamp_targ[target$SAMPID],]
  # dim(selected_resp)
  # dim(responded)
  # dim(resp_wide)
  # dim(target_pruned)
} else {
  target.pruned <- target
  }

```



Add a treatment into it:
```{r}
panel[,'treat':= rep(0,nrow(panel))]
target.pruned[,'treat':=rep(1,nrow(target.pruned))]
```

Now join this data together:
```{r}
alldata <- rbind(panel, target.pruned[1:10], fill=T)
#fill NA
alldata[is.na(panelId),panelId:="9999999999"]
alldata[is.na(sampleId),sampleId:="9999999999"]

head(alldata)
```

Divide target sample into age quantiles (in this case, deciles) and add that to the data:
```{r}
age_q <- quantile(target$age,prob = seq(0,1,0.1)) #this is the full target
alldata[,'age_group' :=  as.integer(cut(alldata$age,breaks = age_q, include.lowest = TRUE))]
alldata[is.na(age_group),age]
alldata$age_group[is.na(alldata$age_group)] <- 10 #highest age-group can get lost; fill it in
```


Load in matching.vars from recodefile
```{r}
recode_map <- fread(recodepath)
matching.vars <- unique(recode_map$common_var)
```

Now carry out the matching. 
```{r}
matching.form <- as.formula(paste0("treat ~ ", paste(matching.vars, collapse=' + ')))
```


We'll have to repeat this process (at least for everything except PS). 
* start empty dataframe initialized with target IDs
* make a copy of the data to alter
* for each i in range:
  + run the matching
  + store the matched IDs
  + store some overall metrics about the match
  + reduce the panel data
* return the match objects

```{r}
matchRatio <- function(data, metric, n, exact = c()){
  # A wrapper for the MatchIt framework to carry out arbitrary numbers of successive matches
  # data must have:
  #   * sampleId
  #   * panelId
  #   * treat
  require(MatchIt)
    
  # assign the dataframe to hold the matching results
  df <- data.frame(matrix(ncol=1, nrow=sum(data$treat==1)))
  names(df) <- c("sampleId")
  df$sampleId <- data$sampleId[data$treat==1]
  
  # assign the object to hold all the matching information
  matches <- vector("list",n)
  
  # make a copy of the passed-in data
  data.copy <- data.frame(data)
  
  # loop over the number of respondents per target
  # if there are issues, can I relax the age groups?
  for(i in 1:n){
    print(paste('i = ',as.character(i)))
    m <- matchit(matching.form, 
                 data = data.copy, exact=exact, method = "nearest", distance = metric)
    controls <- match.data(m, group='control')
    
    try({matches[[i]] <- m
        sampleids <- data.copy[row.names(m$match.matrix), "sampleId"]
        panelids <- data.copy[m$match.matrix,"panelId"]
        ids <- data.frame(sampleId=sampleids, panelId=panelids, stringsAsFactors = F)
        df <- merge(x=df, y=ids, by="sampleId", all.x = TRUE, suffixes=c("",as.character(i)))
        } 
    )
    data.copy <- data.copy[!data.copy$panelId %in% controls$panelId,] # not relying on rownames
    
  }
  return(list("ids"=df, "matches"=matches))
}

```


```{r}
n <- 2
matches = matchRatio(alldata, "mahalanobis", n, exact = c("age_group","gend"))
```


Save the id's of the matches to a file, so I don't lose them--just in case
```{r}
write.csv(
  matches$ids, 
  file=paste0(datadir,"panel/",country,"_selected_wave",wave,"_",format(Sys.time(),"%y%m%d"),".csv"),
  row.names = F)
```

